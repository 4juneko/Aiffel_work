{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4juneko/Aiffel_work/blob/master/16_makeLyrics_50292023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090e17f9",
      "metadata": {
        "id": "090e17f9"
      },
      "source": [
        "# Rubric\n",
        "|평가문항\t|상세기준|내 평가|\n",
        "|--|--|--|\n",
        "|1. 데이터의 전처리 및 구성과정이 체계적으로 진행되었는가?\t|특수문자 제거, 토크나이저 생성, 패딩 처리의 작업들이 빠짐없이 진행되었는가?|O|\n",
        "|2. 가사 텍스트 생성 모델이 정상적으로 동작하는가?\t|텍스트 제너레이션 결과로 생성된 문장이 해석 가능한 문장인가?|O|\n",
        "|3. 텍스트 생성모델이 안정적으로 학습되었는가?\t|텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?|O|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a6f95e",
      "metadata": {
        "id": "04a6f95e",
        "outputId": "143e867a-a1d7-4d1e-858f-1dc7b3fbbeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "source": [
        "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
        "import tensorflow\n",
        "import os, re \n",
        "import tensorflow as tf\n",
        "\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea87fff",
      "metadata": {
        "id": "eea87fff"
      },
      "source": [
        "# Download Data\n",
        "~/aiffel/lyricist/data/lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc66738",
      "metadata": {
        "id": "0dc66738"
      },
      "source": [
        "# Open Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb98d9ec",
      "metadata": {
        "id": "cb98d9ec",
        "outputId": "d543150d-864c-4151-dd1a-6918872ac898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['', '', '[Spoken Intro:]']\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' #os.getenv(x)함수는 환경 변수x의 값을 포함하는 문자열 변수를 반환합니다. txt_file_path 에 \"/root/aiffel/lyricist/data/lyrics/*\" 저장\n",
        "\n",
        "txt_list = glob.glob(txt_file_path) #txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
        "\n",
        "raw_corpus = [] \n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
        "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d48e70e",
      "metadata": {
        "id": "3d48e70e"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feffe25b",
      "metadata": {
        "id": "feffe25b",
        "outputId": "cc56c210-ff4b-414a-a60e-92d1eaad0946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Spoken Intro:]\n",
            "You ever want something \n",
            "that you know you shouldn't have \n",
            "The more you know you shouldn't have it, \n",
            "The more you want it \n",
            "And then one day you get it, \n",
            "It's so good too \n",
            "But it's just like my girl \n"
          ]
        }
      ],
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
        "        \n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0968d3e",
      "metadata": {
        "id": "a0968d3e",
        "outputId": "0f21bec4-1a64-4b4e-8a98-17aa0479b5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1. 소문자로, 공백 없애기\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2. 특수문자 양쪽에 공백\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3. 여러개 공백은 공백 하나로\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4. ^a-zA-Z?.!,¿을 제외하고 공백으로\n",
        "    sentence = sentence.strip() # 5. 양쪽 공백 지우기. 1번에서도 공백 없애기 했는데 두번째이네\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6. 처음에는 start, 끝에는 end 넣기\n",
        "    return sentence\n",
        "\n",
        "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66bcc5aa",
      "metadata": {
        "id": "66bcc5aa",
        "outputId": "6abe1adf-0b01-4ed0-ae58-5222072e9a01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<start> spoken intro <end>',\n",
              " '<start> you ever want something <end>',\n",
              " '<start> that you know you shouldn t have <end>',\n",
              " '<start> the more you know you shouldn t have it , <end>',\n",
              " '<start> the more you want it <end>',\n",
              " '<start> and then one day you get it , <end>',\n",
              " '<start> it s so good too <end>',\n",
              " '<start> but it s just like my girl <end>',\n",
              " '<start> when she s around me <end>',\n",
              " '<start> i just feel so good , so good <end>']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d26e6ee",
      "metadata": {
        "id": "6d26e6ee",
        "outputId": "e74a8239-71b2-42b5-b5ce-d5673957d289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   2 2701 2584 ...    0    0    0]\n",
            " [   2    7  156 ...    0    0    0]\n",
            " [   2   17    7 ...    0    0    0]\n",
            " ...\n",
            " [   2  311    1 ...    0    0    0]\n",
            " [   2  735    5 ...    0    0    0]\n",
            " [   2  735    5 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f727961f1c0>\n"
          ]
        }
      ],
      "source": [
        "# 토큰화 문자를 숫자로...\n",
        "\n",
        "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
        "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "\n",
        "def tokenize(corpus):\n",
        "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
        "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
        "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=7000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\" # out-of-vocabulary, 사전에 없는 단어\n",
        "    )\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=20)  #  토큰의 갯수 20개를 넘어가지 않게\n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1f0234",
      "metadata": {
        "id": "3d1f0234",
        "outputId": "b56f1f7a-a80e-426a-b9df-8967af6f5fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ],
      "source": [
        "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62060ecb",
      "metadata": {
        "id": "62060ecb",
        "outputId": "8e04c0fd-5525-4538-8e9a-6f1de3c3fe10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   2 2701 2584    3    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "[2701 2584    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cf9e2c",
      "metadata": {
        "id": "c7cf9e2c"
      },
      "source": [
        "# Split Data\n",
        "- 단어장의 크기는 12,000 이상 으로 설정하세요!  \n",
        "- 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f138b525",
      "metadata": {
        "id": "f138b525"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input, \n",
        "                                                    test_size=0.2, \n",
        "                                                    shuffle=True, \n",
        "                                                    random_state=1004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ebbb06a",
      "metadata": {
        "id": "7ebbb06a",
        "outputId": "12602500-66c0-4278-ed4e-75b200f522d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(140599, 19) (35150, 19)\n"
          ]
        }
      ],
      "source": [
        "print(enc_train.shape, enc_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a853df",
      "metadata": {
        "id": "10a853df",
        "outputId": "5bab15ec-f87e-4a1f-e870-f6b0674f15d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BUFFER_SIZE = len(enc_train)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        " # tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
        " # tokenize() 함수에서 num_words를 7000개로 선언했기 때문에, tokenizer.num_words의 값은 7000\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f8514a",
      "metadata": {
        "id": "f6f8514a",
        "outputId": "cc99b7b0-9167-4edd-e712-2bedda39adcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9695a1",
      "metadata": {
        "id": "cc9695a1"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cdf6ac",
      "metadata": {
        "id": "94cdf6ac"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
        "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져옵니다!   \n",
        "embedding_size = 512 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
        "hidden_size = 2048 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해하면 좋다.\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa24a3b",
      "metadata": {
        "id": "7fa24a3b",
        "outputId": "00a22449-3d35-4e81-e62a-6e54f150fbaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 19, 7001), dtype=float32, numpy=\n",
              "array([[[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [ 3.45586013e-05,  6.31571980e-04, -2.36904336e-04, ...,\n",
              "         -2.38232693e-04, -5.33414481e-04, -4.75491979e-04],\n",
              "        [ 3.24357999e-04,  1.10829342e-03, -1.45535727e-04, ...,\n",
              "          2.46793817e-04, -6.12090225e-04, -6.05171430e-04],\n",
              "        ...,\n",
              "        [ 2.02675862e-03, -2.21047737e-03, -4.80021769e-03, ...,\n",
              "         -4.76310542e-03,  3.56668816e-03, -7.24541023e-03],\n",
              "        [ 1.97441084e-03, -2.39605829e-03, -5.14235999e-03, ...,\n",
              "         -5.24392724e-03,  3.74352629e-03, -7.47720478e-03],\n",
              "        [ 1.92754797e-03, -2.53265142e-03, -5.41911880e-03, ...,\n",
              "         -5.67735359e-03,  3.90527234e-03, -7.67374178e-03]],\n",
              "\n",
              "       [[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [ 1.44383521e-04,  6.45552180e-04, -7.18899028e-05, ...,\n",
              "         -3.09290073e-04,  1.98377689e-04, -1.03909937e-04],\n",
              "        [ 7.68579775e-04,  5.28809614e-04,  7.40816358e-06, ...,\n",
              "         -4.50583175e-04,  6.20446750e-04, -6.99788943e-05],\n",
              "        ...,\n",
              "        [ 2.38102209e-03, -4.58804716e-04, -1.14239450e-03, ...,\n",
              "         -1.77032768e-03,  2.04658136e-03, -4.35006525e-03],\n",
              "        [ 2.39527365e-03, -8.97744612e-04, -1.92921003e-03, ...,\n",
              "         -2.42482894e-03,  2.34567467e-03, -4.99471137e-03],\n",
              "        [ 2.35489267e-03, -1.29156420e-03, -2.66411039e-03, ...,\n",
              "         -3.06259305e-03,  2.61527533e-03, -5.55574102e-03]],\n",
              "\n",
              "       [[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [ 1.10171866e-04,  9.21536528e-04,  4.16933326e-04, ...,\n",
              "          5.07015036e-04,  4.29004431e-04, -5.65047376e-04],\n",
              "        [ 3.70837952e-04,  6.70447946e-04,  5.78807434e-04, ...,\n",
              "          7.34670262e-04,  4.42910503e-04, -8.21635709e-04],\n",
              "        ...,\n",
              "        [ 1.91473670e-03, -8.93524732e-04, -4.09351150e-03, ...,\n",
              "         -1.82236801e-03,  2.13667518e-03, -4.19367524e-03],\n",
              "        [ 1.89405237e-03, -1.28057320e-03, -4.52907477e-03, ...,\n",
              "         -2.58405693e-03,  2.41176574e-03, -4.85605886e-03],\n",
              "        [ 1.85135507e-03, -1.62719900e-03, -4.91316291e-03, ...,\n",
              "         -3.30453180e-03,  2.66469154e-03, -5.42881340e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [-5.95813501e-04,  1.94394466e-04, -1.54729860e-04, ...,\n",
              "          1.96727531e-04,  5.93965960e-05, -8.74991179e-04],\n",
              "        [-8.85079673e-04, -1.36622184e-04, -5.43764734e-04, ...,\n",
              "          7.11971807e-05, -1.22262732e-04, -1.04776560e-03],\n",
              "        ...,\n",
              "        [ 1.38703082e-03, -2.24762317e-03, -2.71416083e-03, ...,\n",
              "         -2.45624129e-03,  2.77482462e-03, -5.08303801e-03],\n",
              "        [ 1.47124520e-03, -2.49075540e-03, -3.28917266e-03, ...,\n",
              "         -3.11245234e-03,  2.99425237e-03, -5.74016944e-03],\n",
              "        [ 1.52997521e-03, -2.68390216e-03, -3.81176150e-03, ...,\n",
              "         -3.74559034e-03,  3.18800681e-03, -6.28950680e-03]],\n",
              "\n",
              "       [[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [-6.14218006e-05,  5.62941597e-04,  1.05124593e-04, ...,\n",
              "          4.02548321e-04,  7.61415722e-05, -4.62124270e-04],\n",
              "        [-1.48803767e-04,  2.42170805e-04,  1.93316373e-04, ...,\n",
              "          5.22347633e-04, -1.11140558e-04, -4.48175328e-04],\n",
              "        ...,\n",
              "        [-9.95396636e-04, -2.68071017e-04,  1.35801686e-03, ...,\n",
              "          3.19393759e-04,  1.24982631e-04, -1.50680484e-04],\n",
              "        [-5.83658577e-04, -1.94390523e-04,  1.04446430e-03, ...,\n",
              "         -1.92383799e-04,  7.35525449e-04, -1.24202576e-03],\n",
              "        [-2.13102379e-04, -2.90653901e-04,  4.91969753e-04, ...,\n",
              "         -7.91809056e-04,  1.31194969e-03, -2.36751954e-03]],\n",
              "\n",
              "       [[-9.74357608e-05,  3.46262910e-04,  1.01655045e-04, ...,\n",
              "         -5.99511004e-05,  1.63110744e-04, -3.61824030e-04],\n",
              "        [ 1.10171866e-04,  9.21536528e-04,  4.16933326e-04, ...,\n",
              "          5.07015036e-04,  4.29004431e-04, -5.65047376e-04],\n",
              "        [-4.76141213e-05,  1.37078715e-03,  6.14574121e-04, ...,\n",
              "          9.22964129e-04,  2.83980538e-04, -5.52397745e-04],\n",
              "        ...,\n",
              "        [ 2.02849624e-03, -1.78152637e-03, -4.17401828e-03, ...,\n",
              "         -4.03154269e-03,  2.72112596e-03, -7.07761757e-03],\n",
              "        [ 1.99035951e-03, -2.05619796e-03, -4.60648956e-03, ...,\n",
              "         -4.57563531e-03,  2.96229846e-03, -7.38913938e-03],\n",
              "        [ 1.94559002e-03, -2.26934114e-03, -4.97039035e-03, ...,\n",
              "         -5.07680792e-03,  3.18814884e-03, -7.64562422e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571a25a3",
      "metadata": {
        "id": "571a25a3",
        "outputId": "006d6104-4692-4e16-ee11-1e067ea0c2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  3584512   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  20979712  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  33562624  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  14345049  \n",
            "=================================================================\n",
            "Total params: 72,471,897\n",
            "Trainable params: 72,471,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델의 구조를 확인합니다.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8422feaf",
      "metadata": {
        "id": "8422feaf"
      },
      "source": [
        "# Train\n",
        "- 모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요!\n",
        "- val_loss 값은 2.2 아래로 떨어지지 않습니다. 이럴 경우는 batch size를 변경하는 것과 같이 model.fit() 함수에 다양한 인자를 넣어주면 해결될 수도 있습니다\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef5308f",
      "metadata": {
        "scrolled": true,
        "id": "7ef5308f",
        "outputId": "bbb4e0df-53c3-4348-f5c0-09f4e4767de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 335s 601ms/step - loss: 2.6131 - val_loss: 2.2965\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 334s 609ms/step - loss: 2.1442 - val_loss: 2.0735\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 335s 610ms/step - loss: 1.8885 - val_loss: 1.9297\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 336s 611ms/step - loss: 1.6431 - val_loss: 1.8277\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 1.4097 - val_loss: 1.7557\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 336s 613ms/step - loss: 1.1972 - val_loss: 1.7131\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 1.0208 - val_loss: 1.6965\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 0.8873 - val_loss: 1.7051\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 0.8028 - val_loss: 1.7206\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 336s 613ms/step - loss: 0.7570 - val_loss: 1.7397\n"
          ]
        }
      ],
      "source": [
        "# # optimizer와 loss등은 차차 배웁니다\n",
        "# # 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
        "# # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "# # https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "# # 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
        "\n",
        "# # Adam 알고리즘을 구현하는 optimzier이며 어떤 optimzier를 써야할지 모른다면 Adam을 쓰는 것도 방법이다.\n",
        "# # 우리가 학습을 할 때 최대한 틀리지 않는 방향으로 학습을 해야한다.\n",
        "# # 여기서 얼마나 틀리는지(loss)를 알게하는 함수가 손실함수 이다.\n",
        "# # 이 손실함수의 최소값을 찾는 것을 학습의 목표로 하며 여기서 최소값을 찾아가는 과정을 optimization 이라하고\n",
        "# # 이를 수행하는 알고리즘을 optimizer(최적화)라고 한다.\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "# loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "#     from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "#     reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        "# )\n",
        "# # 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "# model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "# history1 = model.fit(dataset, \n",
        "#           epochs=10,\n",
        "#           validation_data = val_dataset) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605556d1",
      "metadata": {
        "id": "605556d1",
        "outputId": "39c8d379-9727-4649-9303-a669726dc684"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # graph\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# loss = history1.history['loss']\n",
        "# val_loss = history1.history['val_loss']\n",
        "\n",
        "# epochs_range = range(1, len(loss)+1)\n",
        "\n",
        "# plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "# plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()\n",
        "# # epoch 3 이후부터 overfit.. \n",
        "# # epoch 3에서 멈추는 것이 낫겠음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413d725e",
      "metadata": {
        "id": "413d725e",
        "outputId": "c5eb2646-edca-4114-f494-a815df1d3eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "549/549 [==============================] - 324s 581ms/step - loss: 2.6089 - val_loss: 2.3252\n",
            "Epoch 2/3\n",
            "549/549 [==============================] - 321s 585ms/step - loss: 2.1902 - val_loss: 2.1235\n",
            "Epoch 3/3\n",
            "549/549 [==============================] - 323s 587ms/step - loss: 1.9691 - val_loss: 1.9843\n"
          ]
        }
      ],
      "source": [
        "# overfit으로 다시 학습 epoch 3\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "history2 = model.fit(dataset, \n",
        "          epochs=3,\n",
        "          validation_data = val_dataset) # 만들어둔 데이터셋으로 모델을 학습한다. 3번 학습을 반복하겠다는 의미다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818591a8",
      "metadata": {
        "id": "818591a8",
        "outputId": "f6b334f7-4741-405b-bf60-8048fc6278c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8117f58a",
      "metadata": {
        "id": "8117f58a"
      },
      "source": [
        "# Save & Load a trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de9190d",
      "metadata": {
        "id": "7de9190d",
        "outputId": "aa639ef5-45ac-45a8-9492-c393c25fc47a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        }
      ],
      "source": [
        "# save trained model\n",
        "from keras.models import load_model\n",
        "# model.save_weights('lyrics_model.h5')\n",
        "\n",
        "model.save('lyrics_model',save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538dbb70",
      "metadata": {
        "id": "538dbb70",
        "outputId": "f6c13313-e4db-4eec-f739-ddb7a98f318a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f72dc89d280>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load saved model\n",
        "# 이 프로젝트의 모델을 자유도가 높은 sub_classing model이기 때문에 structure가 저장되지 않음.\n",
        "# load model할 때 structure를 먼저 부르고 weights를 load하면 됨.\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights\n",
        "# https://wikidocs.net/106897\n",
        "\n",
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "model1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "model1.load_weights(filepath='lyrics_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67446c1",
      "metadata": {
        "id": "b67446c1"
      },
      "outputs": [],
      "source": [
        "#문장생성 함수 정의\n",
        "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
        "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4 \n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated #최종적으로 모델이 생성한 문장을 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939e44b2",
      "metadata": {
        "id": "939e44b2"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d581b23b",
      "metadata": {
        "id": "d581b23b",
        "outputId": "c3f1ab8d-b58d-4893-ba17-432d2fadf4e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i love you , i love you <end> '"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\") #I love를 시작으로 하는 문장... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5fc152d",
      "metadata": {
        "id": "b5fc152d",
        "outputId": "52aeacf7-0306-4034-e77b-3fb70b2af2e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i m gonna marry the night <end> '"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i\") # I로 시작하는 문장. 슬프네.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ac5590",
      "metadata": {
        "id": "05ac5590",
        "outputId": "767bf104-a77f-4928-d3ff-c670099304e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i love you , i love you <end> '"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model1, tokenizer, init_sentence=\"<start> i love\") # 저장했던 모델을 불러와서 문장 생성 저장 전 원래 모델과 같은 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2be0e9d",
      "metadata": {
        "id": "c2be0e9d",
        "outputId": "5bda2ee1-22bc-40bc-e03f-90375b348be0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i m gonna marry the night <end> '"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model1, tokenizer, init_sentence=\"<start> i\") # 저장했던 모델을 불러와서 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "186caf37",
      "metadata": {
        "id": "186caf37",
        "outputId": "3de5f0ea-58eb-4d56-9fc6-d10d00400cfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> you re the only one that s ever gonna say <end> '"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> you\") "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "024440a0",
      "metadata": {
        "id": "024440a0"
      },
      "source": [
        "# Review\n",
        "- Embedding Size와 Hidden Size를 바꾸어 가며 학습함.\n",
        "- embedding_size = 512, hidden_size = 2048에서 loss 2.2 이하의 결과를 얻을 수 있었음.\n",
        "- epochs 3이 넘어가면서 overfit이 되어 3에서 멈춤\n",
        "- model을 저장하여 코드 파일을 열 때마다 저장할 필요없게 하는데 사용한 모델이 자유도가 높은 sub_classing model이기 때문에 structure가 저장되지 않고 weights만 저장됨.\n",
        "- load model시에 structure를 먼저 부르고 load weights => 정상적으로 저장된 모델을 불러올 수 있었음.\n",
        "- I love 뒤의 생성 문장은 I love you. I love you.\n",
        "- I 뒤의 생성 문장은 i m gonna marry the night.\n",
        "- 저장 전의 모델과 저장한 뒤 불러온 모델의 생성 문장은 같았음."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}