{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4juneko/Aiffel_work/blob/master/16_makeLyrics_50292023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "823e614d",
      "metadata": {
        "id": "823e614d"
      },
      "source": [
        "# Rubric\n",
        "|평가문항\t|상세기준|내 평가|\n",
        "|--|--|--|\n",
        "|1. 데이터의 전처리 및 구성과정이 체계적으로 진행되었는가?\t|특수문자 제거, 토크나이저 생성, 패딩 처리의 작업들이 빠짐없이 진행되었는가?|O|\n",
        "|2. 가사 텍스트 생성 모델이 정상적으로 동작하는가?\t|텍스트 제너레이션 결과로 생성된 문장이 해석 가능한 문장인가?|O|\n",
        "|3. 텍스트 생성모델이 안정적으로 학습되었는가?\t|텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?|O|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfae499b",
      "metadata": {
        "id": "cfae499b",
        "outputId": "b86d995e-0c50-46b9-9b92-e67ab3dd8a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "source": [
        "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
        "import tensorflow\n",
        "import os, re \n",
        "import tensorflow as tf\n",
        "\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4308e3cd",
      "metadata": {
        "id": "4308e3cd"
      },
      "source": [
        "# Download Data\n",
        "~/aiffel/lyricist/data/lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd21200",
      "metadata": {
        "id": "7fd21200"
      },
      "source": [
        "# Open Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfde410d",
      "metadata": {
        "id": "cfde410d",
        "outputId": "ae9defb9-c23d-4281-fd31-7bf514757c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['', '', '[Spoken Intro:]']\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' #os.getenv(x)함수는 환경 변수x의 값을 포함하는 문자열 변수를 반환합니다. txt_file_path 에 \"/root/aiffel/lyricist/data/lyrics/*\" 저장\n",
        "\n",
        "txt_list = glob.glob(txt_file_path) #txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
        "\n",
        "raw_corpus = [] \n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
        "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df2e76f",
      "metadata": {
        "id": "6df2e76f"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "105f8b2e",
      "metadata": {
        "id": "105f8b2e",
        "outputId": "9ee6a636-4b55-4e2f-b171-fe05814f7480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Spoken Intro:]\n",
            "You ever want something \n",
            "that you know you shouldn't have \n",
            "The more you know you shouldn't have it, \n",
            "The more you want it \n",
            "And then one day you get it, \n",
            "It's so good too \n",
            "But it's just like my girl \n"
          ]
        }
      ],
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
        "        \n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c97ac0",
      "metadata": {
        "id": "88c97ac0",
        "outputId": "b8ce987b-e0e5-40e0-8363-f191a2acd2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1. 소문자로, 공백 없애기\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2. 특수문자 양쪽에 공백\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3. 여러개 공백은 공백 하나로\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4. ^a-zA-Z?.!,¿을 제외하고 공백으로\n",
        "    sentence = sentence.strip() # 5. 양쪽 공백 지우기. 1번에서도 공백 없애기 했는데 두번째이네\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6. 처음에는 start, 끝에는 end 넣기\n",
        "    return sentence\n",
        "\n",
        "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f9ccd5",
      "metadata": {
        "id": "a7f9ccd5",
        "outputId": "0ff00828-2688-43fd-b7b7-c2f7e02ca1fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<start> spoken intro <end>',\n",
              " '<start> you ever want something <end>',\n",
              " '<start> that you know you shouldn t have <end>',\n",
              " '<start> the more you know you shouldn t have it , <end>',\n",
              " '<start> the more you want it <end>',\n",
              " '<start> and then one day you get it , <end>',\n",
              " '<start> it s so good too <end>',\n",
              " '<start> but it s just like my girl <end>',\n",
              " '<start> when she s around me <end>',\n",
              " '<start> i just feel so good , so good <end>']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7992e89",
      "metadata": {
        "id": "c7992e89",
        "outputId": "59d5b672-1bed-4d24-ae14-1502b2a2a008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   2 2701 2584 ...    0    0    0]\n",
            " [   2    7  156 ...    0    0    0]\n",
            " [   2   17    7 ...    0    0    0]\n",
            " ...\n",
            " [   2  311    1 ...    0    0    0]\n",
            " [   2  735    5 ...    0    0    0]\n",
            " [   2  735    5 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f4d18d0da60>\n"
          ]
        }
      ],
      "source": [
        "# 토큰화 문자를 숫자로...\n",
        "\n",
        "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
        "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "\n",
        "def tokenize(corpus):\n",
        "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
        "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
        "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=7000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\" # out-of-vocabulary, 사전에 없는 단어\n",
        "    )\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=20)  #  토큰의 갯수 20개를 넘어가지 않게\n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5155264",
      "metadata": {
        "id": "c5155264",
        "outputId": "e73ed5ec-da0e-405e-a48a-7c7b965ca346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ],
      "source": [
        "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d541f7ee",
      "metadata": {
        "id": "d541f7ee",
        "outputId": "fa5fe124-0fc6-4515-9a7e-29698b43b57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   2 2701 2584    3    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "[2701 2584    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce54509",
      "metadata": {
        "id": "cce54509"
      },
      "source": [
        "# Split Data\n",
        "- 단어장의 크기는 12,000 이상 으로 설정하세요!  \n",
        "- 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "313d7b3f",
      "metadata": {
        "id": "313d7b3f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                    tgt_input, \n",
        "                                                    test_size=0.2, \n",
        "                                                    shuffle=True, \n",
        "                                                    random_state=1004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c05aec",
      "metadata": {
        "id": "a2c05aec",
        "outputId": "8ba81ebd-7e16-436d-9fd0-d388cad6d6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(140599, 19) (35150, 19)\n"
          ]
        }
      ],
      "source": [
        "print(enc_train.shape, enc_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095836b5",
      "metadata": {
        "id": "095836b5",
        "outputId": "be2cf8ae-bda8-4d69-8e8a-ddaf3052562f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BUFFER_SIZE = len(enc_train)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        " # tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
        " # tokenize() 함수에서 num_words를 7000개로 선언했기 때문에, tokenizer.num_words의 값은 7000\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb6de12",
      "metadata": {
        "id": "afb6de12",
        "outputId": "21d65397-41bd-417b-ee3b-7e20d05a8f43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53e08a2",
      "metadata": {
        "id": "d53e08a2"
      },
      "source": [
        "# get Model & Train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd61cbe",
      "metadata": {
        "id": "ebd61cbe"
      },
      "source": [
        "## Model #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ecf7a6",
      "metadata": {
        "id": "40ecf7a6"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
        "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져옵니다!   \n",
        "embedding_size = 512 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
        "hidden_size = 2048 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해하면 좋다.\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c1b29f",
      "metadata": {
        "id": "a7c1b29f",
        "outputId": "bcb40499-94b4-431a-f5fd-cbad3bfe82c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 19, 7001), dtype=float32, numpy=\n",
              "array([[[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [-2.7238054e-04,  7.3298841e-05,  2.8093325e-04, ...,\n",
              "         -8.4723310e-05, -2.7241983e-04, -2.9063574e-04],\n",
              "        [-1.9288924e-05,  1.0732041e-04,  3.5007947e-04, ...,\n",
              "         -6.8254303e-05, -5.2376679e-04, -1.1860876e-04],\n",
              "        ...,\n",
              "        [ 9.1328705e-04,  9.5561455e-04,  5.6340587e-03, ...,\n",
              "         -2.3685277e-03,  1.2436230e-03, -1.5157579e-03],\n",
              "        [ 9.2674111e-04,  1.0494376e-03,  6.3897017e-03, ...,\n",
              "         -2.3777494e-03,  1.3568959e-03, -1.6269549e-03],\n",
              "        [ 9.4292668e-04,  1.1458620e-03,  6.9993450e-03, ...,\n",
              "         -2.3420798e-03,  1.5015422e-03, -1.6815686e-03]],\n",
              "\n",
              "       [[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [ 5.1432184e-05, -1.3231626e-04,  4.3807502e-04, ...,\n",
              "         -2.1659548e-04,  5.0286908e-06, -8.1572850e-04],\n",
              "        [ 1.5854770e-04,  3.1794774e-05,  7.0464372e-04, ...,\n",
              "         -1.7777906e-04, -2.2501449e-04, -1.0395922e-03],\n",
              "        ...,\n",
              "        [ 5.7036715e-04,  2.2056499e-03,  5.9014987e-03, ...,\n",
              "         -1.7212846e-03,  1.3049309e-03, -1.2366368e-03],\n",
              "        [ 6.4507825e-04,  2.1487123e-03,  6.4575672e-03, ...,\n",
              "         -1.8110687e-03,  1.4080923e-03, -1.3009678e-03],\n",
              "        [ 7.1631611e-04,  2.1118454e-03,  6.9182669e-03, ...,\n",
              "         -1.8452102e-03,  1.5567837e-03, -1.3315495e-03]],\n",
              "\n",
              "       [[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [-1.3623238e-04, -3.8009003e-04,  4.0410762e-04, ...,\n",
              "          3.3399461e-05,  1.4869901e-04, -1.0426860e-04],\n",
              "        [ 1.3763244e-04, -4.7007907e-04,  4.2719932e-04, ...,\n",
              "          2.4760835e-04,  1.7022712e-05, -2.7154959e-04],\n",
              "        ...,\n",
              "        [ 7.5758359e-04,  1.5924290e-03,  8.3603486e-03, ...,\n",
              "         -1.2298228e-03,  1.9942699e-03, -1.5604115e-03],\n",
              "        [ 7.6896430e-04,  1.7013339e-03,  8.4349029e-03, ...,\n",
              "         -1.1855940e-03,  2.2552777e-03, -1.4623009e-03],\n",
              "        [ 7.6874974e-04,  1.8023315e-03,  8.4744301e-03, ...,\n",
              "         -1.1401600e-03,  2.4926956e-03, -1.3630518e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [-6.5391941e-04, -3.5979212e-04, -3.4826389e-04, ...,\n",
              "          4.0288255e-04,  4.9861906e-06,  1.0128436e-04],\n",
              "        [-8.7115751e-04, -3.8004859e-04, -6.0600386e-04, ...,\n",
              "          1.7252855e-04, -9.6011008e-06,  6.4403622e-04],\n",
              "        ...,\n",
              "        [ 8.8928890e-04,  1.6942263e-03,  5.6951460e-03, ...,\n",
              "         -8.4361352e-04,  1.7314912e-03, -5.4298615e-04],\n",
              "        [ 9.6502982e-04,  1.7311681e-03,  6.3083330e-03, ...,\n",
              "         -9.9321315e-04,  1.9199350e-03, -7.3296146e-04],\n",
              "        [ 1.0132582e-03,  1.7685293e-03,  6.8052509e-03, ...,\n",
              "         -1.0938128e-03,  2.1098375e-03, -8.6933986e-04]],\n",
              "\n",
              "       [[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [-3.1250043e-04, -3.4043763e-04,  2.3374456e-04, ...,\n",
              "         -2.2570023e-04,  3.9196407e-04, -6.8186906e-05],\n",
              "        [-9.4821931e-05, -3.0901181e-04,  5.7270733e-04, ...,\n",
              "         -4.5755104e-04,  6.4751366e-04, -1.8043882e-04],\n",
              "        ...,\n",
              "        [ 9.0754248e-04,  6.4299174e-04,  6.6786003e-03, ...,\n",
              "         -1.3436709e-03,  6.6097063e-04, -2.9248188e-03],\n",
              "        [ 1.0192703e-03,  8.3513162e-04,  7.1564107e-03, ...,\n",
              "         -1.4072697e-03,  9.4548124e-04, -2.7514021e-03],\n",
              "        [ 1.0946771e-03,  1.0192203e-03,  7.5361440e-03, ...,\n",
              "         -1.4364179e-03,  1.2457117e-03, -2.5599219e-03]],\n",
              "\n",
              "       [[-1.1430148e-04, -1.5759865e-04,  8.0295147e-05, ...,\n",
              "          8.1421334e-05, -3.9826264e-05, -1.2749693e-04],\n",
              "        [-4.1170727e-04, -1.9490812e-04,  2.1185580e-05, ...,\n",
              "          4.7929885e-04, -2.5600501e-04, -3.5570899e-04],\n",
              "        [-7.1124750e-04,  1.5193252e-04,  1.7724575e-04, ...,\n",
              "          4.0959485e-04, -3.8109324e-04, -2.6476002e-04],\n",
              "        ...,\n",
              "        [ 6.6331966e-04,  1.4623639e-03,  7.9654157e-03, ...,\n",
              "         -1.2888312e-03,  1.4048879e-03, -2.0717941e-03],\n",
              "        [ 7.3152100e-04,  1.5660671e-03,  8.2198046e-03, ...,\n",
              "         -1.2857888e-03,  1.6876115e-03, -1.9670951e-03],\n",
              "        [ 7.7923673e-04,  1.6687297e-03,  8.3972095e-03, ...,\n",
              "         -1.2663606e-03,  1.9606685e-03, -1.8510303e-03]]], dtype=float32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12aafdb7",
      "metadata": {
        "id": "12aafdb7",
        "outputId": "fbde3932-f553-4718-93f8-68a0158a94f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  3584512   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  20979712  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  33562624  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  14345049  \n",
            "=================================================================\n",
            "Total params: 72,471,897\n",
            "Trainable params: 72,471,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델의 구조를 확인합니다.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4220336f",
      "metadata": {
        "id": "4220336f"
      },
      "source": [
        "### Train\n",
        "- 모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요!\n",
        "- val_loss 값은 2.2 아래로 떨어지지 않습니다. 이럴 경우는 batch size를 변경하는 것과 같이 model.fit() 함수에 다양한 인자를 넣어주면 해결될 수도 있습니다\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42fb6117",
      "metadata": {
        "scrolled": true,
        "id": "42fb6117",
        "outputId": "aa258cf6-d723-4f5a-ad59-61db00c996b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 335s 601ms/step - loss: 2.6131 - val_loss: 2.2965\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 334s 609ms/step - loss: 2.1442 - val_loss: 2.0735\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 335s 610ms/step - loss: 1.8885 - val_loss: 1.9297\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 336s 611ms/step - loss: 1.6431 - val_loss: 1.8277\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 1.4097 - val_loss: 1.7557\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 336s 613ms/step - loss: 1.1972 - val_loss: 1.7131\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 1.0208 - val_loss: 1.6965\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 0.8873 - val_loss: 1.7051\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 336s 612ms/step - loss: 0.8028 - val_loss: 1.7206\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 336s 613ms/step - loss: 0.7570 - val_loss: 1.7397\n"
          ]
        }
      ],
      "source": [
        "# optimizer와 loss등은 차차 배웁니다\n",
        "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
        "\n",
        "# Adam 알고리즘을 구현하는 optimzier이며 어떤 optimzier를 써야할지 모른다면 Adam을 쓰는 것도 방법이다.\n",
        "# 우리가 학습을 할 때 최대한 틀리지 않는 방향으로 학습을 해야한다.\n",
        "# 여기서 얼마나 틀리는지(loss)를 알게하는 함수가 손실함수 이다.\n",
        "# 이 손실함수의 최소값을 찾는 것을 학습의 목표로 하며 여기서 최소값을 찾아가는 과정을 optimization 이라하고\n",
        "# 이를 수행하는 알고리즘을 optimizer(최적화)라고 한다.\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "history1 = model.fit(dataset, \n",
        "          epochs=10,\n",
        "          validation_data = val_dataset) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2076f0",
      "metadata": {
        "id": "af2076f0",
        "outputId": "0764df1d-4329-42b3-f24c-370a604c1550"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history1.history['loss']\n",
        "val_loss = history1.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 속도가 느리고 training과 validation의 loss가 점점 벌어져 overfit의 조짐이 보여 모델을 좀 더 심플하게 할 필요가 있겠음."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bdf727",
      "metadata": {
        "id": "e5bdf727"
      },
      "source": [
        "### Use Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35235873",
      "metadata": {
        "scrolled": true,
        "id": "35235873",
        "outputId": "5a600a78-cd31-4502-a941-fbea9a776990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 332s 601ms/step - loss: 1.8836 - val_loss: 1.9089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "549/549 [==============================] - 332s 605ms/step - loss: 1.5978 - val_loss: 1.7996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10\n",
            "549/549 [==============================] - 333s 606ms/step - loss: 1.3351 - val_loss: 1.7289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "549/549 [==============================] - 333s 606ms/step - loss: 1.1130 - val_loss: 1.6978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10\n",
            "549/549 [==============================] - 333s 605ms/step - loss: 0.9450 - val_loss: 1.6968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10\n",
            "172/549 [========>.....................] - ETA: 3:29 - loss: 0.8106"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "\n",
        "check_point_cb = callbacks.ModelCheckpoint('lyrics_model', \n",
        "                                           save_format='tf')\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, \n",
        "                                            monitor='val_loss',\n",
        "                                            restore_best_weights=True)\n",
        "history = model.fit(dataset, \n",
        "                    epochs=10,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[check_point_cb, early_stopping_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a359a5",
      "metadata": {
        "id": "b6a359a5"
      },
      "source": [
        "## Model #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3786259",
      "metadata": {
        "id": "e3786259",
        "outputId": "f45341cb-2053-4497-a47e-56559aa6d653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  3584512   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  7176025   \n",
            "=================================================================\n",
            "Total params: 25,448,793\n",
            "Trainable params: 25,448,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
        "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져옵니다!   \n",
        "embedding_size = 512 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
        "hidden_size = 1024 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해하면 좋다.\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다.\n",
        "\n",
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)\n",
        "\n",
        "# 모델의 구조를 확인합니다.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bd9e3b",
      "metadata": {
        "id": "e2bd9e3b",
        "outputId": "e778b5e2-966b-4783-f8a3-8bccca944c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 114s 195ms/step - loss: 2.7718 - val_loss: 2.4819\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 113s 205ms/step - loss: 2.3690 - val_loss: 2.3081\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 113s 206ms/step - loss: 2.2295 - val_loss: 2.2139\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 113s 205ms/step - loss: 2.1295 - val_loss: 2.1487\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 114s 206ms/step - loss: 2.0445 - val_loss: 2.0959\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 113s 206ms/step - loss: 1.9664 - val_loss: 2.0502\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 113s 206ms/step - loss: 1.8918 - val_loss: 2.0111\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 114s 207ms/step - loss: 1.8213 - val_loss: 1.9780\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 114s 207ms/step - loss: 1.7532 - val_loss: 1.9495\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 114s 207ms/step - loss: 1.6863 - val_loss: 1.9252\n"
          ]
        }
      ],
      "source": [
        "# overfit으로 다시 학습 epoch 3\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "history2 = model.fit(dataset, \n",
        "          epochs=10,\n",
        "          validation_data = val_dataset) # 만들어둔 데이터셋으로 모델을 학습한다. 3번 학습을 반복하겠다는 의미다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19723788",
      "metadata": {
        "id": "19723788",
        "outputId": "e3d56fb2-9ffa-4e1f-e005-7f8cb4505a18"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297a7c1b",
      "metadata": {
        "id": "297a7c1b"
      },
      "source": [
        "### Use Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea18124",
      "metadata": {
        "id": "1ea18124",
        "outputId": "095c3d88-88f2-420e-bb23-2cdecc42c8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 128s 223ms/step - loss: 2.7668 - val_loss: 2.4608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "549/549 [==============================] - 123s 223ms/step - loss: 2.3476 - val_loss: 2.2836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 2.1953 - val_loss: 2.1806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 2.0793 - val_loss: 2.1055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.9770 - val_loss: 2.0431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.8825 - val_loss: 1.9941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.7930 - val_loss: 1.9524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.7059 - val_loss: 1.9200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.6211 - val_loss: 1.8891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10\n",
            "549/549 [==============================] - 123s 224ms/step - loss: 1.5373 - val_loss: 1.8645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "\n",
        "check_point_cb = callbacks.ModelCheckpoint('lyrics_model5', \n",
        "                                           save_format='tf')\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=10, \n",
        "                                            monitor='val_loss',\n",
        "                                            restore_best_weights=True)\n",
        "history5 = model.fit(dataset, \n",
        "                    epochs=10,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[check_point_cb, early_stopping_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7463583c",
      "metadata": {
        "id": "7463583c",
        "outputId": "f0fd7d2a-b68a-4ae1-c0d0-19ce75db811d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history5.history['loss']\n",
        "val_loss = history5.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd74b512",
      "metadata": {
        "id": "dd74b512"
      },
      "source": [
        "# Save & Load a trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697d25e5",
      "metadata": {
        "id": "697d25e5",
        "outputId": "ef0298ea-1f79-4aca-b185-2a76bf4dc8ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lyrics_model5/assets\n"
          ]
        }
      ],
      "source": [
        "# save trained model\n",
        "from keras.models import load_model\n",
        "# model.save_weights('lyrics_model.h5')\n",
        "\n",
        "model.save('lyrics_model5',save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad86568c",
      "metadata": {
        "id": "ad86568c",
        "outputId": "985fbff7-14ae-47e3-8411-b2a1938566f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4d2d3b9ee0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load saved model\n",
        "# 이 프로젝트의 모델을 자유도가 높은 sub_classing model이기 때문에 structure가 저장되지 않음.\n",
        "# load model할 때 structure를 먼저 부르고 weights를 load하면 됨.\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights\n",
        "# https://wikidocs.net/106897\n",
        "\n",
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "model5 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "model5.load_weights(filepath='lyrics_model5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49df30cf",
      "metadata": {
        "id": "49df30cf"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2c9bf9",
      "metadata": {
        "id": "1f2c9bf9"
      },
      "outputs": [],
      "source": [
        "#문장생성 함수 정의\n",
        "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
        "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4 \n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated #최종적으로 모델이 생성한 문장을 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507af230",
      "metadata": {
        "id": "507af230",
        "outputId": "23ce369d-dd78-4fc0-ebf1-c3d82681d249"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i love you , liberian girl <end> '"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\") #I love를 시작으로 하는 문장... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10107290",
      "metadata": {
        "id": "10107290",
        "outputId": "591a76a2-59b5-4ee9-d508-40445fa45d52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i m gonna make it alright <end> '"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i\") # I로 시작하는 문장. 슬프네.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e695b6ae",
      "metadata": {
        "id": "e695b6ae",
        "outputId": "bee12e3f-6a20-4e11-e68f-d758976bf77c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i love you , i m not gonna crack <end> '"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model1, tokenizer, init_sentence=\"<start> i love\") # 저장했던 모델을 불러와서 문장 생성 저장 전 원래 모델과 같은 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad6677f",
      "metadata": {
        "id": "2ad6677f",
        "outputId": "1d5d6c15-a4bb-424b-d197-7175f643e403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i m the one gon hold you down yeah , yeah <end> '"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model1, tokenizer, init_sentence=\"<start> i\") # 저장했던 모델을 불러와서 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb308ff",
      "metadata": {
        "id": "1cb308ff",
        "outputId": "cb24729c-6cb9-42fb-b026-96586072ea6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i love you , liberian girl <end> '"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model5, tokenizer, init_sentence=\"<start> i love\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb20f91",
      "metadata": {
        "id": "acb20f91",
        "outputId": "03c58399-4100-40dd-83be-b5e6e215e7b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<start> i m gonna make it alright <end> '"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model5, tokenizer, init_sentence=\"<start> i\") "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485a302b",
      "metadata": {
        "id": "485a302b"
      },
      "source": [
        "# Review\n",
        "- Embedding Size와 Hidden Size를 바꾸어 가며 학습함.\n",
        "- embedding_size = 512, hidden_size = 2048에서 loss 2.2 이하의 결과를 얻을 수 있었음. => 학습속도가 느려(613ms/step)\n",
        "- 속도가 느리고 training과 validation의 loss가 점점 벌어져 overfit의 조짐이 보여 모델을 좀 더 심플하게 할 필요가 있겠음.\n",
        "- embedding_size = 512, hidden_size = 1024로 다시 학습함. 224ms/step로 속도는 2배 이상 빨라짐 epochs = 10일 때 1.8645로 앞선 모델보다 성능이 더 좋음. \n",
        "- callback을 사용하였으나 epochs 설정을 10으로 하여 중간에 멈추지는 않았음. \n",
        "- model을 저장하여 코드 파일을 열 때마다 저장할 필요없게 하는데 사용한 모델이 자유도가 높은 sub_classing model이기 때문에 structure가 저장되지 않고 weights만 저장됨.\n",
        "- load model시에 structure를 먼저 부르고 load weights => 정상적으로 저장된 모델을 불러올 수 있었음.\n",
        "- 저장 전의 모델과 저장한 뒤 불러온 모델의 생성 문장은 같았음.\n",
        "    - I love 로 시작하는 생성 문장은 i love you , liberian girl\n",
        "    - I 로 시작하는 생성 문장은 i m gonna make it alright\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe54d0b",
      "metadata": {
        "id": "1fe54d0b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}